<h1 align="center">
  SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes
</h1>


This is the code for SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes.

 * [Project Page](https://yihua7.github.io/SC-GS-web/)
 * [Paper](https://yihua7.github.io/SC-GS-web/materials/SC_GS_Arxiv.pdf)

<div align="center">
  <img src="./assets/teaser.png" width="100%" height="100%">
</div>

*Given (a) an image sequence from a monocular dynamic video, we propose to represent the motion with a set of sparse control points, which can be used to drive 3D Gaussians for high-fidelity rendering.Our approach enables both (b) dynamic view synthesis and (c) motion editing due to the motion representation based on sparse control points*


#### Quantitative comparison on D-NeRF datasets. 

We present the average PSNR/SSIM/LPIPS (VGG) values for novel view synthesis on dynamic scenes from D-NeRF, with each cell colored to indicate the best, second best, and third best.
<div align="center">
  <img src="./assets/D-NeRF-Results.png" width="100%" height="100%">
</div>

 
